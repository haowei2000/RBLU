wandb: True # use wandb to log the results
force_regenerate: True # forced to regenerate the data even if the result file exists
language: zh
task_list:
  - medical
  - legal
  - financial
  # - code
batch_size: 8
model:
  model_name: glm
  model_path:
    llama: /public/model/hub/llm-research/meta-llama-3-8b-instruct
    # gemma: /public/model/hub/AI-ModelScope/gemma-2-9b-it
    glm: /public/model/hub/ZhipuAI/glm-4-9b-chat
    qwen: /public/model/hub/qwen/qwen2-7b-instruct

# The following is the default config for the data generation
# Please dont change the config in the data generation script unless you know what you are doing
loop_count: 5
data:
  doc_count: 500
  min_length: 1
  max_length: 2000
tokenizer_kwargs:
  padding: True
  max_length: 512
  truncation: True
  add_special_tokens: True
gen_kwargs:
  max_new_tokens: 1000
